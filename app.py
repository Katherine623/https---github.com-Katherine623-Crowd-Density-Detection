import streamlit as st
import cv2
import numpy as np
from ultralytics import YOLO
from PIL import Image
import tempfile
from collections import deque

st.set_page_config(page_title="Crowd Density Detection", layout="centered")
st.title("è¡Œäººæ“æ“ åº¦åµæ¸¬ Crowd Density Detection (äºº/ã¡ + ROI + é è­¦)")

# -------------- Sidebarï¼šå®‰å…¨å·¥ç¨‹ç›¸é—œåƒæ•¸ --------------
st.sidebar.header("ğŸ§­ å€åŸŸèˆ‡é–€æª»è¨­å®š")
use_roi = st.sidebar.checkbox("å•Ÿç”¨ ROIï¼ˆç™¾åˆ†æ¯”è£åˆ‡ï¼‰", value=False,
                              help="è‹¥ä¸å‹¾é¸ï¼Œä½¿ç”¨æ•´å€‹ç•«é¢ç•¶ä½œç›£æ§å€åŸŸã€‚")

if use_roi:
    col1, col2 = st.sidebar.columns(2)
    x0p = col1.slider("ROI å·¦(%)", 0, 90, 0, 1)
    y0p = col2.slider("ROI ä¸Š(%)", 0, 90, 0, 1)
    x1p = col1.slider("ROI å³(%)", 10, 100, 100, 1)
    y1p = col2.slider("ROI ä¸‹(%)", 10, 100, 100, 1)
else:
    x0p, y0p, x1p, y1p = 0, 0, 100, 100

AREA_M2 = st.sidebar.number_input("ç›£æ§å€åŸŸå¯¦éš›é¢ç© (ã¡)", min_value=1.0, value=20.0, step=1.0,
                                  help="è«‹å¡«å¯¦æ¸¬æˆ–åœ–é¢ä¼°ç®—çš„å€åŸŸé¢ç©ï¼›å¯†åº¦=äººæ•¸/ã¡")

DENSITY_WARN = st.sidebar.number_input("è­¦å‘Šé–€æª» (äºº/ã¡)", min_value=0.5, value=5.0, step=0.5)
DENSITY_DANGER = st.sidebar.number_input("å±éšªé–€æª» (äºº/ã¡)", min_value=1.0, value=6.5, step=0.5)

HOLD_SECONDS = st.sidebar.number_input("é€£çºŒè¶…æ¨™ç§’æ•¸ï¼ˆè§¸ç™¼é è­¦ï¼‰", min_value=1, value=5, step=1)
st.sidebar.caption("ä¾ crowd safety æ–‡ç»ï¼š>5 äºº/ã¡ é«˜é¢¨éšªã€6â€“7 äºº/ã¡ æ¥µå±éšªï¼›10â€“30 ç§’æ˜¯é—œéµåæ‡‰çª—ã€‚")

# -------------- æ¨¡å‹ --------------
@st.cache_resource
def load_model():
    return YOLO("yolov8n.pt")

model = load_model()

# -------------- åŠŸèƒ½å‡½å¼ --------------
def apply_roi(img, x0p, y0p, x1p, y1p):
    """ä»¥ç™¾åˆ†æ¯”è£åˆ‡ ROIï¼›å›å‚³ ROI å½±åƒèˆ‡åœ¨åŸåœ–ä¸Šçš„ä½ç½®"""
    H, W = img.shape[:2]
    x0 = int(W * x0p / 100.0)
    y0 = int(H * y0p / 100.0)
    x1 = int(W * x1p / 100.0)
    y1 = int(H * y1p / 100.0)
    x0, y0 = max(0, x0), max(0, y0)
    x1, y1 = min(W, x1), min(H, y1)
    roi = img[y0:y1, x0:x1].copy()
    return roi, (x0, y0, x1, y1)

def detect_count_people(img_bgr):
    """å›å‚³ (person_count, boxes)ï¼›boxesç‚º(å·¦ä¸Šå³ä¸‹)åº§æ¨™åˆ—è¡¨"""
    results = model(img_bgr)
    boxes = results[0].boxes
    person_count = 0
    out_boxes = []
    for box in boxes:
        if int(box.cls[0]) == 0:  # class 0 = person
            person_count += 1
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            out_boxes.append((x1, y1, x2, y2))
    return person_count, out_boxes

def draw_result(base_img, global_boxes, density, level_text, color, roi_rect=None, seconds_over=None):
    img = base_img.copy()
    # ROI å¤–æ¡†
    if roi_rect is not None:
        x0, y0, x1, y1 = roi_rect
        cv2.rectangle(img, (x0, y0), (x1, y1), (180, 180, 180), 2)

    # äººæ¡†
    for (x1, y1, x2, y2) in global_boxes:
        cv2.rectangle(img, (x1, y1), (x2, y2), (60, 220, 60), 2)

    # æ–‡å­—
    ybase = 40
    cv2.putText(img, f"Density: {density:.2f} /m^2  [{level_text}]",
                (20, ybase), cv2.FONT_HERSHEY_SIMPLEX, 1.0, color, 2)
    ybase += 35
    if seconds_over is not None:
        cv2.putText(img, f"Over-threshold for: {seconds_over:.1f}s",
                    (20, ybase), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)
        ybase += 35

    # å¯†åº¦æ¢
    bar_x, bar_y, bar_w, bar_h = 20, ybase, 320, 26
    cv2.rectangle(img, (bar_x, bar_y), (bar_x + bar_w, bar_y + bar_h), (200, 200, 200), 2)
    # Normalizeåˆ°å±éšªé–€æª»
    ratio = min(density / max(DENSITY_DANGER, 1e-6), 1.0)
    cv2.rectangle(img, (bar_x, bar_y), (bar_x + int(bar_w * ratio), bar_y + bar_h), color, -1)
    return img

def level_from_density(d):
    if d >= DENSITY_DANGER:
        return "Danger", (0, 0, 255)
    elif d >= DENSITY_WARN:
        return "Warning", (0, 165, 255)
    else:
        return "Normal", (0, 200, 0)

# -------------- è¼¸å…¥ä¾†æº --------------
option = st.radio('é¸æ“‡è¼¸å…¥ä¾†æº', ['ä¸Šå‚³åœ–ç‰‡', 'ä¸Šå‚³å½±ç‰‡', 'å½±ç‰‡é€£çµ', 'æ‹ç…§'])

# -------------- åœ–ç‰‡ --------------
if option == 'ä¸Šå‚³åœ–ç‰‡':
    uploaded_file = st.file_uploader('è«‹ä¸Šå‚³åœ–ç‰‡', type=['jpg', 'jpeg', 'png'])
    if uploaded_file is not None:
        image = Image.open(uploaded_file).convert('RGB')
        img_np = np.array(image)
        img_bgr = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)

        # ROI
        roi_img, (x0, y0, x1, y1) = apply_roi(img_bgr, x0p, y0p, x1p, y1p)
        count, boxes = detect_count_people(roi_img)
        density = count / max(AREA_M2, 1e-6)

        # å°‡ ROI å…§çš„ boxes è½‰å›å…¨åœ–åº§æ¨™
        global_boxes = [(x1_ + x0, y1_ + y0, x2_ + x0, y2_ + y0) for (x1_, y1_, x2_, y2_) in boxes]
        level_text, color = level_from_density(density)
        out = draw_result(img_bgr, global_boxes, density, level_text, color, (x0, y0, x1, y1))

        st.image(cv2.cvtColor(out, cv2.COLOR_BGR2RGB), caption='åµæ¸¬çµæœï¼ˆäºº/ã¡ï¼‰', use_column_width=True)
        st.success(f"ROI é¢ç© = {AREA_M2:.2f} ã¡,  è¨ˆæ•¸ = {count} äºº,  å¯†åº¦ = {density:.2f} äºº/ã¡,  ç­‰ç´š = {level_text}")

# -------------- å½±ç‰‡ï¼ˆæœ¬åœ°ä¸Šå‚³/ç¶²å€ï¼‰å…±ç”¨è¿´åœˆ --------------
def run_video(cap):
    # ä¼° FPSï¼›è‹¥è®€ä¸åˆ°å°±å‡è¨­ 30
    fps_read = cap.get(cv2.CAP_PROP_FPS)
    fps = fps_read if fps_read and fps_read > 0 else 30.0

    stframe = st.empty()
    over_hist = deque(maxlen=int(HOLD_SECONDS * fps))
    seconds_over = 0.0

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        roi_img, (x0, y0, x1, y1) = apply_roi(frame, x0p, y0p, x1p, y1p)
        count, boxes = detect_count_people(roi_img)
        density = count / max(AREA_M2, 1e-6)
        level_text, color = level_from_density(density)

        # è¶…æ¨™ç´€éŒ„
        over_hist.append(1 if level_text != "Normal" else 0)
        seconds_over = sum(over_hist) / fps

        global_boxes = [(bx1 + x0, by1 + y0, bx2 + x0, by2 + y0) for (bx1, by1, bx2, by2) in boxes]
        vis = draw_result(frame, global_boxes, density, level_text, color, (x0, y0, x1, y1), seconds_over)

        # è§¸ç™¼é è­¦ï¼ˆä½ å¯åœ¨é€™è£¡ç™¼ APIã€å¯« logã€æ’­æ”¾è²éŸ³ç­‰ï¼‰
        if seconds_over >= HOLD_SECONDS and level_text != "Normal":
            cv2.putText(vis, "ALERT: CROWD RISK!", (20, 200), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0,0,255), 3)

        stframe.image(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB), channels='RGB')

# å½±ç‰‡ï¼šæœ¬åœ°ä¸Šå‚³
elif option == 'ä¸Šå‚³å½±ç‰‡':
    uploaded_video = st.file_uploader('è«‹ä¸Šå‚³å½±ç‰‡', type=['mp4', 'avi', 'mov'])
    if uploaded_video is not None:
        tfile = tempfile.NamedTemporaryFile(delete=False)
        tfile.write(uploaded_video.read())
        cap = cv2.VideoCapture(tfile.name)
        run_video(cap)
        cap.release()

# å½±ç‰‡ï¼šé€£çµ
elif option == 'å½±ç‰‡é€£çµ':
    video_url = st.text_input('è«‹è²¼ä¸Šå½±ç‰‡é€£çµï¼ˆmp4/avi/mov ç›´é€£ç¶²å€ï¼‰')
    if video_url:
        cap = cv2.VideoCapture(video_url)
        if not cap.isOpened():
            st.error('ç„¡æ³•é–‹å•Ÿå½±ç‰‡é€£çµï¼Œè«‹ç¢ºèªç¶²å€æ­£ç¢ºä¸”ç‚ºå…¬é–‹å½±ç‰‡ã€‚')
        else:
            run_video(cap)
            cap.release()

# æ‹ç…§
elif option == 'æ‹ç…§':
    camera_img = st.camera_input('è«‹æ‹ç…§ä¸Šå‚³')
    if camera_img is not None:
        image = Image.open(camera_img).convert('RGB')
        img_np = np.array(image)
        img_bgr = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)

        roi_img, (x0, y0, x1, y1) = apply_roi(img_bgr, x0p, y0p, x1p, y1p)
        count, boxes = detect_count_people(roi_img)
        density = count / max(AREA_M2, 1e-6)

        global_boxes = [(x1_ + x0, y1_ + y0, x2_ + x0, y2_ + y0) for (x1_, y1_, x2_, y2_) in boxes]
        level_text, color = level_from_density(density)
        out = draw_result(img_bgr, global_boxes, density, level_text, color, (x0, y0, x1, y1))

        st.image(cv2.cvtColor(out, cv2.COLOR_BGR2RGB), caption='åµæ¸¬çµæœï¼ˆäºº/ã¡ï¼‰', use_column_width=True)
        st.success(f"ROI é¢ç© = {AREA_M2:.2f} ã¡,  è¨ˆæ•¸ = {count} äºº,  å¯†åº¦ = {density:.2f} äºº/ã¡,  ç­‰ç´š = {level_text}")
